<!--
# @title Developer Guide
-->
# Cloud Stove Developer Guide

## Architecture Overview

The Cloud Stove currently consists of two main components: The backend API implemented using Ruby on Rails and the front end application implemented using AngularJS. The figure below shows a high-level overview of the Cloud Stove components (modeled using the Cloud Stove) as currently deployed:

![cloud stove architecture](images/architecture.png)

The backend is largely a standard Rails app with ActiveRecord RDBMS data store. Recommendations are generated by transforming the modeled applications, constraints, and available provider resources into a [MiniZinc](http://www.minizinc.org) model and solving the optimal resource allocation problem using [Google or-tools](https://developers.google.com/optimization/) in asynchronously executed background jobs. 

The Angular front end is implemented in TypeScript and currently exposes most features of the backend API.

## Data Model

The figure below shows an overview of the Cloud Stove data model. Note that the {User `User`} model was omitted from the figure to reduce clutter.

![data model ERD](images/erd.svg)

All `Ingredient`, `DeploymentRecommendation`, `*Workload`, and `*Constraint` records are owned by exactly one user. By default, a user can only see and modify entities that belong to them. There is one exception, though. Template instances (discussed below) created by an admin are visible to all users.

### `Base` Model

If you need to store a lot of (semi-)structured metadata for an entity (that you don't need to query on), the `Base` model provides a `more_attributes` hash that will be serialized as a JSON object. For additional comfort, `Base` lets you define accessors for attributes stored in the serialized hash. Similar to regular attribute accessors, `ma_reader `, `ma_writer`, and `ma_accessor` will create attribute readers, writers, or both. Using accessors you can easily migrate attributes from the serialized hash to database columns when needed. When you add the column, you just need to go over all records and copy the new attribute values from the `more_attributes` hash. To use the `Base` model, inherit from `Base` and make sure that a `more_attributes` column of type `text` is part of your table.

For more information, see the documentation of {Base}.

### Ingredients

![Ingredients and Constraints](images/erd-ingredient.svg)

{Ingredient}s are at the core of the Cloud Stove data model. Application Templates, applications, and application components are modeled as hierarchical collections of ingredients. Application templates (or archetypes) and applications are at the root of ingredient trees, i.e., they have no parent (their `parent_id` is `nil`). Application components are linked to an application using `parent_id`. Currently, applications are flat collections of components, i.e., all components are directly assigned to one parent application. In the future, we will support reusing applications as components in other applications to create application ensembles. Templates and their components are marked by setting the `is_template` flag to `true` (The {SameIsTemplateValidator} ensures that ingredient hierarchies remain consistent).

### Constraints

![Ingredients and Constraints](images/erd-ingredient-constraint.svg)

All application and component properties and interactions that will later influence deployment recommendations are modeled as constraints in the Cloud Stove. As shown in the figure above, several constraint types are currently supported:

* **{DependencyConstraint}**: Component dependencies, i.e., components that communicate with each other, can be represented using dependency constraints. These component dependencies are subsequently used in combination with traffic workloads to model expected network traffic between components of an application.
* **{CpuConstraint}**: This constraint represents the minimum amount of CPU performance required for deploying the given application component. CPU performance is currently represented as the number of required "standard" CPU cores. In the future, we will migrate towards a Cloud Stove Processing Unit (CSPU) that assesses CPU performance based on automated, periodic instance benchmarks.
* **{RamConstraint}**: Similar to the CPU constraint, this constraint represents the minimum amount of RAM required (in MB) to successfully deploy the given component in production.
* **{ScalingConstraint}**: This constraint specifies the maximum number of instances this component can be distributed across. To prevent horizontal scaling for a component, set `max_num_instances` to `1` , or set it to `0` for unlimited horizontal scaling.
* **{PreferredRegionAreaConstraint}**: Deployment recommendations for applications and individual components can be constrained to certain geographical regions using this constraint. Currently, the following regions are supported: EU, US (North America), Asia-Pacific, South America. More regions will be added as providers open data centers in other regions.
* **{ProviderConstraint}**: This constraint allows you to restrict recommendations to a given set of cloud providers. The list of allowed providers is stored as a serialized array of provider ids.

Constraints are always attached to an ingredient. By default, a constraint applies only to the ingredient it is attached to. However, provider and region area constraints also apply all children of an ingredient.

Except for dependency constraints, there are not many reasons to directly create constraints for components. Usually, constraints are generated as part of a deployment scenario that is derived from modeled workloads.

### Workloads

![workloads](images/erd-ingredient-workload.svg)

Workloads are at the core of the deployment scenario analysis in the Cloud Stove. The different types of workloads provide an abstraction from concrete component constraints and allow users to specify infrastructure requirements for application components based on the requirements of a typical user of the deployed application. Several workload types are supported:

* **{CpuWorkload}**: The required CPU performance for a component is modeled with two parameters. First, the expected number of users that can be handled with one CSPU (i.e., currently one vCPU core) is specified in `cspu_user_capacity`. Additionally, the expected speedup of each additional CSPU is specified using the `parallelism` attribute.
* **{RamWorkload}**: Component memory requirements are modeled based on three parameters. We assume that a component needs a minimum amount of RAM for basic functionality (`ram_mb_required`), and that a certain number of users can be served with this base amount (`ram_mb_required_user_capacity`). Finally, the amount of memory required for each additional user is captured in `ram_mb_growth_per_user`.
* **{ScalingWorkload}**: With this basic scaling workload, components can be constrained to vertical scaling or allowed to horizontally scale across an arbitrary number of instances. Set `scale_ingredient` accordingly.
* **{TrafficWorkload}**: Using the traffic workload, users can model the expected number and size of customer requests the application should be able to serve. The three parameters represent the size of a typical application response (`request_size_kb`), the average number of customer requests per session (`requests_per_visit`), and the expected number of user sessions over a month (`visits_per_month`). We plan to use this data to generate traffic cost estimations along with deployment recommendations.



### Providers and Resources

![providers and resources](images/erd-provider-resource.svg)

To pull in available resources from providers, the Cloud Stove uses a pluggable provider updater mechanism. Provider updaters inherit from the {ProviderUpdater} base class. The base class will dynamically load all available provider updaters in the `app/provider_updaters/` directory when {ProviderUpdater#providers} is called. To schedule background jobs executing all available updaters, call {ProviderUpdater#update_providers}.

Currently supported providers:

* {AmazonUpdater Amazon EC2}
* {GoogleUpdater Google Compute Engine}
* {AzureUpdater Microsoft Azure VMs}
* {RackspaceUpdater Rackspace Cloud Servers}
* {DigitalOceanUpdater Digital Ocean}
* {JoyentUpdater Joyent VMs}
* {AtlanticNetUpdater Atlantic.net}

Provider data update can be initiated in the provider list in the backend or using the `jobs:update_providers`  rake task.

A provider updater is a background job that initiates fetching and parsing of provider resources in `#perform`. An updater is expected to maintain a {Provider} record with a unique name that is created upon first use and subsequently updated (not re-created). Similarly, all attached {Resource}s should be created and updated to always reflect the current state of the provider offering. Provider and resource ids should remain stable.

*Note:* There is no versioning mechanism for stored provider resources. Only the current state of provider offerings should be stored. To preserve resource states when deployment recommendations are generated, recommendations store the generated MiniZinc data files on creation.

### Deployment Recommendations

![deployment recommendations](images/erd-deploymentrecommendation.svg)

{DeploymentRecommendation Deployment recommendations} capture resource recommendations for deploying applications (ingredient topologies). Each ingredient in an application is assumed to be deployed on a set of identical resources (cloud instances). A deployment recommendation is created for an application root instance using {Ingredient#construct_recommendations}, passing an array of target numbers of simulated users. In the regular request flow, deployment recommendations are created and computed using the {ConstructRecommendationsJob} and {EvaluateRecommendationJob} background jobs respectively.

When creating a new deployment recommendation, the current state of the application, along with resource specifications from the specified provider (or all providers if no provider id was specified) are transformed into [MiniZinc](http://minizinc.org) data files. The generated data files are then used to solve the resource assignment problem using the Cloud Stove MiniZinc model in `lib/horizontal-scaling.mzn`. Currently, the [Google or-tools](https://developers.google.com/optimization/) optimization tool set is used to solve the optimization problem.

### Using different optimizer backends
Since the Cloud Stove uses on MiniZinc to represent optimization problems, you can easily change optimization tools as long as there is a MiniZinc binding. 

To use a different optimizer, you want to add the FlatZinc interpreter binaries to the `vendor/minizinc/bin` directory, and place the included MiniZinc library files in `vendor/minzinc/share/minizinc/<interpreter-name>`. For details on how to prepare a suitable MiniZinc distribution, check out the combined [MiniZinc/or-tools distribution](https://github.com/inz/minizinc-dist) that we use for the Cloud Stove. The `release` script shows how to combine a basic MiniZinc distribution with a third party optimization tool.

To actually invoke another optimizer when generating recommendations, change the MiniZinc command in {DeploymentRecommendation#evaluate}. For instance, to generate recommendations using the included G12 optimizer, change  `command` to:

```ruby
command = "minizinc -G g12-fd #{minizinc_model} #{resources.path} #{ingredients.path}"
```

### Extending or modifying the optimization model

As mentioned above, the Cloud Stove optimization model can be found at `lib/horizontal-scaling.mzn`. If you want to change or replace this model, make sure that the structure of the `output` statement is not changed. You can change the active optimization model by modifying the path in {DeploymentRecommendation#minizinc_model}. The data files necessary for performing the optimization are generated in {DeploymentRecommendation#generate_resources_data} and {DeploymentRecommendation#generate_ingredients_data}, creating MiniZinc data representations of available provider resources and the modeled application respectively. If you change the model to expect additional parameters from the application topology, you will have to make sure to generate them in {DeploymentRecommendation#generate_ingredients_data}.


## Authentication

devise_token_auth

angular2-token

## API

api docs here

---

Update the figures in this guide using the following commands:

```shell
bundle exec erd --notation=uml --polymorphism=true --inheritance \
  --attributes=false --exclude="User,Delayed::Backend::ActiveRecord::Job" \
  --filename=./docs/images/erd --filetype=svg
bundle exec erd --notation=uml --title='Ingredients' --only="Ingredient" \
  --inheritance --polymorphism --attributes=foreign_keys,content \
  --filename=./docs/images/erd-ingredient --filetype=svg
bundle exec erd --notation=uml --title='Ingredients and Constraints' \
  --only="Ingredient,Constraint,DependencyConstraint,CpuConstraint,RamConstraint,PreferredRegionAreaConstraint,ProviderConstraint,ScalingConstraint" \
  --inheritance --polymorphism --attributes=foreign_keys,content \
  --filename=./docs/images/erd-ingredient-constraint --filetype=svg
bundle exec erd --notation=uml --title='Ingredients and Workloads' \
  --only="Ingredient,CpuWorkload,RamWorkload,TrafficWorkload,ScalingWorkload" \
  --inheritance --polymorphism --attributes=foreign_keys,content \
  --filename=./docs/images/erd-ingredient-workload --filetype=svg
bundle exec erd --notation=uml --title='Providers and Resources' \
  --only="Provider,Resource" \
  --inheritance --polymorphism --attributes=foreign_keys,content \
  --filename=./docs/images/erd-provider-resource --filetype=svg
bundle exec erd --notation=uml --title='Deployment Recommendations' \
  --only="DeploymentRecommendation" \
  --inheritance --polymorphism --attributes=foreign_keys,content \
  --filename=./docs/images/erd-deploymentrecommendation --filetype=svg
```

